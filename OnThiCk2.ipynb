{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng quan dữ liệu:\n",
      "a. Số lượng giá trị thiếu của cột 'drop': 0\n",
      "b. Kích thước dữ liệu: (30000, 25)\n",
      "c. Số lượng giá trị thiếu của cột 'limit': 0\n",
      "d. Số lượng giá trị thiếu của cột 'clear': 0\n",
      "e. Số lượng giá trị thiếu của cột 'delete': 0\n",
      "f. Số lượng giá trị thiếu của cột 'remove': 0\n",
      "g. Số lượng giá trị thiếu của các cột c1, d1, f1, ..., c6, d6, f6:\n",
      "c1    0\n",
      "d1    0\n",
      "f1    0\n",
      "c2    0\n",
      "d2    0\n",
      "f2    0\n",
      "c3    0\n",
      "d3    0\n",
      "f3    0\n",
      "c4    0\n",
      "d4    0\n",
      "f4    0\n",
      "c5    0\n",
      "d5    0\n",
      "f5    0\n",
      "c6    0\n",
      "d6    0\n",
      "f6    0\n",
      "dtype: int64\n",
      "h. Số lượng giá trị thiếu của cột 'order': 0\n"
     ]
    }
   ],
   "source": [
    "# Đọc dữ liệu\n",
    "import pandas as pd\n",
    "\n",
    "# Đọc file Excel được cung cấp\n",
    "df = pd.read_excel(\"Dethi_data.xlsx\")\n",
    "\n",
    "# a. Kiểm tra số lượng giá trị thiếu của cột drop\n",
    "missing_drop = df['drop'].isnull().sum()\n",
    "\n",
    "# b. Kích thước dữ liệu\n",
    "data_shape = df.shape\n",
    "\n",
    "# c - h. Kiểm tra số lượng giá trị thiếu của các cột\n",
    "missing_limit = df['limit'].isnull().sum()\n",
    "missing_clear = df['clear'].isnull().sum()\n",
    "missing_delete = df['delete'].isnull().sum()\n",
    "missing_remove = df['remove'].isnull().sum()\n",
    "\n",
    "# Kiểm tra các cột c1, d1, f1, ..., c6, d6, f6\n",
    "missing_c_d_f = df[['c1', 'd1', 'f1', 'c2', 'd2', 'f2', 'c3', 'd3', 'f3', 'c4', 'd4', 'f4', 'c5', 'd5', 'f5', 'c6', 'd6', 'f6']].isnull().sum()\n",
    "\n",
    "# Kiểm tra cột order\n",
    "missing_order = df['order'].isnull().sum()\n",
    "\n",
    "# In kết quả\n",
    "print(\"Tổng quan dữ liệu:\")\n",
    "print(f\"a. Số lượng giá trị thiếu của cột 'drop': {missing_drop}\")\n",
    "print(f\"b. Kích thước dữ liệu: {data_shape}\")\n",
    "print(f\"c. Số lượng giá trị thiếu của cột 'limit': {missing_limit}\")\n",
    "print(f\"d. Số lượng giá trị thiếu của cột 'clear': {missing_clear}\")\n",
    "print(f\"e. Số lượng giá trị thiếu của cột 'delete': {missing_delete}\")\n",
    "print(f\"f. Số lượng giá trị thiếu của cột 'remove': {missing_remove}\")\n",
    "print(f\"g. Số lượng giá trị thiếu của các cột c1, d1, f1, ..., c6, d6, f6:\\n{missing_c_d_f}\")\n",
    "print(f\"h. Số lượng giá trị thiếu của cột 'order': {missing_order}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a. Số lượng mẫu trong tập dữ liệu df_train: 27000\n",
      "b. Số lượng mẫu trong tập dữ liệu df_test: 3000\n",
      "e. Kích thước df_train: (27000, 25)\n"
     ]
    }
   ],
   "source": [
    "# Câu 2 \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tách dữ liệu thành df_train và df_test với random_state=10\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=10)\n",
    "\n",
    "# Kiểm tra số lượng mẫu trong df_train và df_test\n",
    "num_train_samples = df_train.shape[0]\n",
    "num_test_samples = df_test.shape[0]\n",
    "\n",
    "# Kiểm tra kích thước của df_train\n",
    "df_train_shape = df_train.shape\n",
    "\n",
    "# In kết quả\n",
    "print(f\"a. Số lượng mẫu trong tập dữ liệu df_train: {num_train_samples}\")\n",
    "print(f\"b. Số lượng mẫu trong tập dữ liệu df_test: {num_test_samples}\")\n",
    "print(f\"e. Kích thước df_train: {df_train_shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2664 thuộc về df_train\n",
      "1392 thuộc về df_train\n",
      "18817 thuộc về df_train\n",
      "485 thuộc về df_train\n",
      "26435 thuộc về df_train\n",
      "28018 thuộc về df_train\n",
      "17729 thuộc về df_train\n",
      "29200 thuộc về df_train\n",
      "7294 thuộc về df_train\n",
      "17674 thuộc về df_train\n",
      "24449 thuộc về df_test\n",
      "4368 thuộc về df_test\n",
      "5750 thuộc về df_test\n",
      "13544 thuộc về df_test\n",
      "5330 thuộc về df_test\n",
      "20413 thuộc về df_test\n",
      "1297 thuộc về df_test\n",
      "3907 thuộc về df_test\n",
      "20455 thuộc về df_test\n",
      "5201 thuộc về df_test\n"
     ]
    }
   ],
   "source": [
    "# Câu 3\n",
    "\n",
    "# Lấy danh sách giá trị của cột 'order' trong tập huấn luyện và kiểm thử\n",
    "train_orders = df_train['order'].tolist()\n",
    "test_orders = df_test['order'].tolist()\n",
    "\n",
    "# Kiểm tra các giá trị cụ thể thuộc tập nào\n",
    "check_values = [2664, 1392, 18817, 485, 26435, \n",
    "                28018, 17729, 29200, 7294, 17674, \n",
    "                24449, 4368, 5750, 13544, 5330, \n",
    "                20413, 1297, 3907, 20455, 5201]\n",
    "\n",
    "for value in check_values:\n",
    "    if value in train_orders:\n",
    "        print(f\"{value} thuộc về df_train\")\n",
    "    elif value in test_orders:\n",
    "        print(f\"{value} thuộc về df_test\")\n",
    "    else:\n",
    "        print(f\"{value} không tìm thấy trong dữ liệu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared: 0.30035000239307363\n",
      "Mean Absolute Error (MAE): 82906.84797769552\n"
     ]
    }
   ],
   "source": [
    "# Câu 4: \n",
    "# Import các thư viện cần thiết\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Bước 1: Đọc dữ liệu\n",
    "file_path = 'Dethi_data.xlsx'  # Thay đường dẫn file nếu cần\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Lấy các đặc trưng (features) và target\n",
    "features = ['c1', 'd1', 'f1', 'c2', 'd2', 'f2', 'f3', 'f4', 'f5', 'f6']\n",
    "X = data[features]\n",
    "y = data['limit']\n",
    "\n",
    "# Bước 2: Chia dữ liệu thành tập huấn luyện và kiểm thử (random_state=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "\n",
    "# Bước 3: Huấn luyện mô hình Multiple Linear Regression (MLR)\n",
    "mlr_model = LinearRegression()\n",
    "mlr_model.fit(X_train, y_train)\n",
    "\n",
    "# Bước 4: Dự đoán trên tập kiểm thử\n",
    "y_pred = mlr_model.predict(X_test)\n",
    "\n",
    "# Bước 5: Tính toán các đại lượng đánh giá\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# In kết quả\n",
    "print(\"R-Squared:\", r_squared)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213447.42417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Câu 5:\n",
    "\n",
    "# Đầu vào của giá trị đặc trưng\n",
    "input_values = [-1.0, 9640.0, 15134.0, -2.0, 7404.0, 0, 7002.0, 8167.0, 3996.0, 2000.0]\n",
    "\n",
    "# Dự báo giá trị limit bằng mô hình MLR đã huấn luyện\n",
    "predicted_limit = mlr_model.predict([input_values])[0]\n",
    "\n",
    "# Làm tròn giá trị dự báo tới 5 chữ số thập phân\n",
    "predicted_limit_rounded = round(predicted_limit, 5)\n",
    "\n",
    "# In kết quả\n",
    "print(predicted_limit_rounded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [30000, 27000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Sử dụng GridSearchCV để tìm giá trị k tốt nhất\u001b[39;00m\n\u001b[0;32m     11\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(knn, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# In ra giá trị k tối ưu\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiá trị k tối ưu: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:806\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_refit_for_multimetric(scorers)\n\u001b[0;32m    804\u001b[0m     refit_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit\n\u001b[1;32m--> 806\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    807\u001b[0m fit_params \u001b[38;5;241m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m    809\u001b[0m cv_orig \u001b[38;5;241m=\u001b[39m check_cv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:455\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \n\u001b[0;32m    438\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 455\u001b[0m check_consistent_length(\u001b[38;5;241m*\u001b[39mresult)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [30000, 27000]"
     ]
    }
   ],
   "source": [
    "# Câu 6\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Giả sử df là toàn bộ dữ liệu (bao gồm các cột đặc trưng và nhãn)\n",
    "# Tách các cột đặc trưng và nhãn\n",
    "X = df[['c1', 'd1', 'f1', 'c2', 'd2', 'f2', 'f3', 'f4', 'f5', 'f6']]  # Các cột đặc trưng\n",
    "y = df['limit']  # Cột nhãn 'limit'\n",
    "\n",
    "# Chia tập dữ liệu thành train (90%) và test (10%) với random_state=10\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\n",
    "\n",
    "# Cài đặt mô hình KNN với k=20\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "# Huấn luyện mô hình KNN\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập huấn luyện\n",
    "y_pred_train = knn.predict(X_train)\n",
    "\n",
    "# Tính độ chính xác trên tập huấn luyện\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# In kết quả độ chính xác\n",
    "print(f\"Accuracy của mô hình KNN với k=20: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order', 'limit', 'clear', 'drop', 'delete', 'remove', 'c1', 'c2', 'c3',\n",
       "       'c4', 'c5', 'c6', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'f1', 'f2', 'f3',\n",
       "       'f4', 'f5', 'f6', 'default'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of knn_feature: 0.2682000000\n"
     ]
    }
   ],
   "source": [
    "# Câu 7:\n",
    "X_train_sampled, _, y_train_sampled, _ = train_test_split(X_scaled, y, test_size=0.9, random_state=10)\n",
    "\n",
    "# Huấn luyện mô hình KNN với một tập dữ liệu nhỏ hơn\n",
    "knn.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# Dự đoán xác suất trên tập huấn luyện mẫu\n",
    "knn_probabilities = knn.predict_proba(X_train_sampled)\n",
    "\n",
    "# Chọn xác suất cao nhất cho mỗi mẫu\n",
    "knn_feature = knn_probabilities.max(axis=1)\n",
    "\n",
    "# Tính giá trị trung bình của knn_feature\n",
    "mean_knn_feature = knn_feature.mean()\n",
    "\n",
    "# In kết quả làm tròn đến 10 chữ số thập phân\n",
    "print(f\"Mean of knn_feature: {mean_knn_feature:.10f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giá trị nhỏ nhất: -339603.0000000000\n",
      "Trung bình: 16750.6649518518\n",
      "Phương sai: 1588283758.5961916447\n",
      "Giá trị lớn nhất: 1684259.0000000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Giả sử df là DataFrame chứa tất cả dữ liệu và các đặc trưng cần thiết\n",
    "# Chọn các cột đặc trưng cho tập huấn luyện (các cột có tên từ c1, c2, ..., f6)\n",
    "X_train = df[['c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6']]\n",
    "\n",
    "# Bỏ các giá trị NaN khỏi X_train\n",
    "X_train_clean = X_train.dropna()  # Bỏ các dòng có giá trị NaN\n",
    "\n",
    "# Tính toán các giá trị yêu cầu\n",
    "min_value = X_train_clean.min().min()  # Giá trị nhỏ nhất trong ma trận\n",
    "mean_value = X_train_clean.mean().mean()  # Trung bình các giá trị trong ma trận\n",
    "variance_value = X_train_clean.var().mean()  # Phương sai các giá trị trong ma trận\n",
    "max_value = X_train_clean.max().max()  # Giá trị lớn nhất trong ma trận\n",
    "\n",
    "# In các kết quả làm tròn đến 10 chữ số thập phân\n",
    "print(f\"Giá trị nhỏ nhất: {min_value:.10f}\")\n",
    "print(f\"Trung bình: {mean_value:.10f}\")\n",
    "print(f\"Phương sai: {variance_value:.10f}\")\n",
    "print(f\"Giá trị lớn nhất: {max_value:.10f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_hybrid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, r2_score\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Giả sử bạn đã có dự báo từ mô hình Hybrid và MLR\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# y_test là nhãn thực tế của tập kiểm thử\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# MAE và R-Squared cho mô hình Hybrid\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m mae_hybrid \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, y_pred_hybrid)\n\u001b[0;32m      9\u001b[0m r2_hybrid \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_pred_hybrid)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# MAE và R-Squared cho mô hình MLR\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred_hybrid' is not defined"
     ]
    }
   ],
   "source": [
    "# Câu 9:\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Giả sử bạn đã có dự báo từ mô hình Hybrid và MLR\n",
    "# y_test là nhãn thực tế của tập kiểm thử\n",
    "\n",
    "# MAE và R-Squared cho mô hình Hybrid\n",
    "mae_hybrid = mean_absolute_error(y_test, y_pred_hybrid)\n",
    "r2_hybrid = r2_score(y_test, y_pred_hybrid)\n",
    "\n",
    "# MAE và R-Squared cho mô hình MLR\n",
    "mae_mlr = mean_absolute_error(y_test, y_pred_mlr)\n",
    "r2_mlr = r2_score(y_test, y_pred_mlr)\n",
    "\n",
    "# In kết quả\n",
    "print(f\"MAE của Hybrid Model: {mae_hybrid}\")\n",
    "print(f\"R-Squared của Hybrid Model: {r2_hybrid}\")\n",
    "print(f\"MAE của MLR Model: {mae_mlr}\")\n",
    "print(f\"R-Squared của MLR Model: {r2_mlr}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
